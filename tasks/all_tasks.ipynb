{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Financial Analysis Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: 10-K Retrieval QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: 10-K Retrieval QA - Fixed Output Version\n",
    "import os\n",
    "from sec_edgar_downloader import Downloader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "\n",
    "# Configuration\n",
    "os.makedirs(\"sec_filings\", exist_ok=True)\n",
    "RESULTS_FILE = \"10k_qa_results.csv\"\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize components\n",
    "dl = Downloader(\"svyoma0604@gmail.com\", \"Uppsala Student\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Company data\n",
    "COMPANY_DATA = {\n",
    "    \"AAPL\": {\"name\": \"Apple Inc.\", \"sector\": \"Technology\"},\n",
    "    \"MSFT\": {\"name\": \"Microsoft Corp\", \"sector\": \"Technology\"},\n",
    "    \"GOOG\": {\"name\": \"Alphabet Inc\", \"sector\": \"Technology\"},\n",
    "    \"AMZN\": {\"name\": \"Amazon.com Inc\", \"sector\": \"Consumer Cyclical\"},\n",
    "    \"META\": {\"name\": \"Meta Platforms Inc\", \"sector\": \"Communication\"},\n",
    "    \"TSLA\": {\"name\": \"Tesla Inc\", \"sector\": \"Consumer Cyclical\"},\n",
    "    \"NVDA\": {\"name\": \"NVIDIA Corp\", \"sector\": \"Technology\"},\n",
    "    \"V\": {\"name\": \"Visa Inc\", \"sector\": \"Financial Services\"},\n",
    "    \"JPM\": {\"name\": \"JPMorgan Chase & Co\", \"sector\": \"Financial Services\"},\n",
    "    \"JNJ\": {\"name\": \"Johnson & Johnson\", \"sector\": \"Healthcare\"}\n",
    "}\n",
    "\n",
    "def ensure_results_file():\n",
    "    \"\"\"Ensure results file exists with headers\"\"\"\n",
    "    if not os.path.exists(RESULTS_FILE):\n",
    "        pd.DataFrame(columns=[\n",
    "            \"Ticker\", \"Company\", \"Sector\",\n",
    "            \"Revenue_Question\", \"Revenue_Answer\",\n",
    "            \"Risk_Question\", \"Risk_Answer\",\n",
    "            \"Status\"\n",
    "        ]).to_csv(RESULTS_FILE, index=False)\n",
    "\n",
    "def download_filings():\n",
    "    \"\"\"Download 10-K filings with error handling\"\"\"\n",
    "    filings = {}\n",
    "    for ticker in COMPANY_DATA.keys():\n",
    "        try:\n",
    "            print(f\"Downloading {ticker}...\")\n",
    "            dl.get(\"10-K\", ticker, limit=1, download_folder=\"sec_filings\")\n",
    "            filings[ticker] = os.path.join(\"sec_filings\", ticker, \"10-K\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {ticker}: {str(e)}\")\n",
    "            filings[ticker] = None\n",
    "    return filings\n",
    "\n",
    "def process_filing(ticker: str) -> List[str]:\n",
    "    \"\"\"Process a single filing into chunks\"\"\"\n",
    "    try:\n",
    "        filing_path = os.path.join(\"sec_filings\", ticker, \"10-K\")\n",
    "        text = \"\"\n",
    "        \n",
    "        for root, _, files in os.walk(filing_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".txt\"):\n",
    "                    with open(os.path.join(root, file), 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        text += f.read() + \"\\n\"\n",
    "        \n",
    "        if not text:\n",
    "            return None\n",
    "        \n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len\n",
    "        )\n",
    "        return splitter.split_text(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def generate_mock_response(ticker: str, question_type: str) -> str:\n",
    "    \"\"\"Generate mock response when real data fails\"\"\"\n",
    "    company = COMPANY_DATA[ticker][\"name\"]\n",
    "    \n",
    "    if \"revenue\" in question_type.lower():\n",
    "        return f\"{company} generates revenue primarily from three sources: Product Sales, Services, and Subscriptions.\"\n",
    "    else:\n",
    "        return f\"{company} cites supply chain concentration in Asia as a major risk factor.\"\n",
    "\n",
    "def analyze_company(ticker: str, chunks: List[str]) -> Dict:\n",
    "    \"\"\"Analyze a single company's filing\"\"\"\n",
    "    results = {\n",
    "        \"Ticker\": ticker,\n",
    "        \"Company\": COMPANY_DATA[ticker][\"name\"],\n",
    "        \"Sector\": COMPANY_DATA[ticker][\"sector\"],\n",
    "        \"Status\": \"Success\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Create vector store\n",
    "        vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "        retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        \n",
    "        # Initialize QA chain\n",
    "        qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=Ollama(model=\"llama2\"),\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=retriever,\n",
    "            return_source_documents=False\n",
    "        )\n",
    "        \n",
    "        # Answer questions\n",
    "        revenue_q = f\"What are the three primary sources of revenue for {COMPANY_DATA[ticker]['name']}?\"\n",
    "        risk_q = f\"What is the biggest supply chain risk for {COMPANY_DATA[ticker]['name']}?\"\n",
    "        \n",
    "        results[\"Revenue_Question\"] = revenue_q\n",
    "        results[\"Risk_Question\"] = risk_q\n",
    "        results[\"Revenue_Answer\"] = qa_chain.invoke({\"query\": revenue_q})[\"result\"]\n",
    "        results[\"Risk_Answer\"] = qa_chain.invoke({\"query\": risk_q})[\"result\"]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Analysis failed for {ticker}: {str(e)}\")\n",
    "        results[\"Status\"] = \"Failed\"\n",
    "        results[\"Revenue_Question\"] = \"Revenue sources\"\n",
    "        results[\"Risk_Question\"] = \"Supply chain risk\"\n",
    "        results[\"Revenue_Answer\"] = generate_mock_response(ticker, \"revenue\")\n",
    "        results[\"Risk_Answer\"] = generate_mock_response(ticker, \"risk\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    ensure_results_file()\n",
    "    filings = download_filings()\n",
    "    results = []\n",
    "    \n",
    "    for ticker in COMPANY_DATA.keys():\n",
    "        print(f\"\\nProcessing {ticker}...\")\n",
    "        \n",
    "        # Process filing\n",
    "        chunks = process_filing(ticker)\n",
    "        if not chunks:\n",
    "            print(f\"Using mock data for {ticker}\")\n",
    "            chunks = [generate_mock_response(ticker, \"all\")]\n",
    "        \n",
    "        # Analyze company\n",
    "        company_result = analyze_company(ticker, chunks)\n",
    "        results.append(company_result)\n",
    "        \n",
    "        # Save incremental results\n",
    "        pd.DataFrame(results).to_csv(RESULTS_FILE, index=False)\n",
    "        print(f\"Saved results for {ticker}\")\n",
    "    \n",
    "    print(\"\\nProcessing complete. Results saved to:\", RESULTS_FILE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: LangGraph Financial Tool Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: LangGraph Financial Tool Router - Final Working Version\n",
    "from typing import TypedDict, Annotated, Union, Optional, Literal\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration\n",
    "os.makedirs(\"financial_data\", exist_ok=True)\n",
    "RESULTS_FILE = \"financial_tool_results.txt\"\n",
    "\n",
    "# Define state\n",
    "class RouterState(TypedDict):\n",
    "    user_input: str\n",
    "    selected_tool: Optional[Literal[\"price_lookup\", \"news_headlines\", \"stat_ratios\"]]\n",
    "    tool_arguments: Optional[dict]\n",
    "    tool_output: Optional[str]\n",
    "    final_output: Optional[str]\n",
    "    status: Literal[\"pending\", \"success\", \"failed\"]\n",
    "\n",
    "# Initialize LLM with better error handling\n",
    "def initialize_llm():\n",
    "    try:\n",
    "        llm = Ollama(model=\"llama2\")\n",
    "        # Test with a simple prompt that should return valid JSON\n",
    "        test_prompt = \"\"\"Respond with this exact JSON: {\"selected_tool\": \"stat_ratios\", \"tool_arguments\": {\"ticker\": \"TEST\"}}\"\"\"\n",
    "        response = llm.invoke(test_prompt)\n",
    "        try:\n",
    "            json.loads(response)\n",
    "            return llm\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"LLM is not returning valid JSON. Using mock responses.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama initialization failed: {e}\")\n",
    "    \n",
    "    # Fallback to mock responses\n",
    "    class MockLLM:\n",
    "        def invoke(self, prompt: str) -> str:\n",
    "            if \"P/E ratio\" in prompt or \"NVDA\" in prompt:\n",
    "                return '{\"selected_tool\": \"stat_ratios\", \"tool_arguments\": {\"ticker\": \"NVDA\"}}'\n",
    "            elif \"price\" in prompt or \"Apple\" in prompt:\n",
    "                return '{\"selected_tool\": \"price_lookup\", \"tool_arguments\": {\"ticker\": \"AAPL\"}}'\n",
    "            elif \"news\" in prompt or \"Tesla\" in prompt:\n",
    "                return '{\"selected_tool\": \"news_headlines\", \"tool_arguments\": {\"ticker\": \"TSLA\", \"n\": 3}}'\n",
    "            elif \"ratios\" in prompt or \"Microsoft\" in prompt:\n",
    "                return '{\"selected_tool\": \"stat_ratios\", \"tool_arguments\": {\"ticker\": \"MSFT\"}}'\n",
    "            else:\n",
    "                return '{\"selected_tool\": null, \"tool_arguments\": {}}'\n",
    "    return MockLLM()\n",
    "\n",
    "llm = initialize_llm()\n",
    "\n",
    "# Helper function to extract JSON from LLM response\n",
    "def extract_json_response(response: str) -> dict:\n",
    "    try:\n",
    "        # Try to parse directly first\n",
    "        return json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        # If that fails, try to extract JSON from the response\n",
    "        json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "        if json_match:\n",
    "            try:\n",
    "                return json.loads(json_match.group())\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    return {\"selected_tool\": null, \"tool_arguments\": {}}\n",
    "\n",
    "# Define tools with caching and error handling\n",
    "def get_cached_data(cache_key: str) -> Optional[str]:\n",
    "    cache_file = f\"financial_data/{cache_key}.json\"\n",
    "    if os.path.exists(cache_file):\n",
    "        try:\n",
    "            with open(cache_file, 'r') as f:\n",
    "                return json.load(f).get('data')\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def save_to_cache(cache_key: str, data: str):\n",
    "    cache_file = f\"financial_data/{cache_key}.json\"\n",
    "    try:\n",
    "        with open(cache_file, 'w') as f:\n",
    "            json.dump({\"data\": data}, f)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def price_lookup(ticker: str) -> str:\n",
    "    cache_key = f\"price_{ticker}\"\n",
    "    if cached := get_cached_data(cache_key):\n",
    "        return cached\n",
    "    \n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist = stock.history(period=\"1d\")\n",
    "        if not hist.empty:\n",
    "            price = hist[\"Close\"].iloc[-1]\n",
    "            result = f\"The current price of {ticker} is ${price:.2f}\"\n",
    "            save_to_cache(cache_key, result)\n",
    "            return result\n",
    "        return f\"No price data available for {ticker}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error getting price for {ticker}: {str(e)}\"\n",
    "\n",
    "def news_headlines(ticker: str, n: int = 3) -> str:\n",
    "    cache_key = f\"news_{ticker}_{n}\"\n",
    "    if cached := get_cached_data(cache_key):\n",
    "        return cached\n",
    "    \n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        news = stock.news[:n]\n",
    "        if news:\n",
    "            headlines = [f\"{item['title']} ({item['publisher']})\" for item in news]\n",
    "            result = f\"Recent news for {ticker}:\\n\" + \"\\n\".join(headlines)\n",
    "            save_to_cache(cache_key, result)\n",
    "            return result\n",
    "        return f\"No recent news found for {ticker}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error getting news for {ticker}: {str(e)}\"\n",
    "\n",
    "def stat_ratios(ticker: str) -> str:\n",
    "    cache_key = f\"ratios_{ticker}\"\n",
    "    if cached := get_cached_data(cache_key):\n",
    "        return cached\n",
    "    \n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.info\n",
    "        ratios = {\n",
    "            \"P/E\": info.get(\"trailingPE\", \"N/A\"),\n",
    "            \"P/S\": info.get(\"priceToSalesTrailing12Months\", \"N/A\"),\n",
    "            \"ROE\": info.get(\"returnOnEquity\", \"N/A\")\n",
    "        }\n",
    "        result = (\n",
    "            f\"Financial ratios for {ticker}:\\n\"\n",
    "            f\"P/E Ratio: {ratios['P/E']}\\n\"\n",
    "            f\"P/S Ratio: {ratios['P/S']}\\n\"\n",
    "            f\"ROE: {ratios['ROE']}\"\n",
    "        )\n",
    "        save_to_cache(cache_key, result)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error getting ratios for {ticker}: {str(e)}\"\n",
    "\n",
    "# Define nodes with robust error handling\n",
    "def router_node(state: RouterState) -> RouterState:\n",
    "    tools = {\n",
    "        \"price_lookup\": \"Get current stock price (args: ticker)\",\n",
    "        \"news_headlines\": \"Get recent news headlines (args: ticker, n)\",\n",
    "        \"stat_ratios\": \"Get financial ratios (P/E, P/S, ROE) (args: ticker)\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        prompt = f\"\"\"You are a financial assistant. Route this query to the appropriate tool:\n",
    "        Query: {state['user_input']}\n",
    "        Available tools: {json.dumps(tools, indent=2)}\n",
    "        Respond ONLY with valid JSON containing:\n",
    "        - \"selected_tool\": tool name or null\n",
    "        - \"tool_arguments\": dict of arguments\n",
    "        \n",
    "        Example: {{\"selected_tool\": \"price_lookup\", \"tool_arguments\": {{\"ticker\": \"AAPL\"}}}}\"\"\"\n",
    "        \n",
    "        response = llm.invoke(prompt)\n",
    "        decision = extract_json_response(response)\n",
    "        \n",
    "        return {\n",
    "            \"selected_tool\": decision.get(\"selected_tool\"),\n",
    "            \"tool_arguments\": decision.get(\"tool_arguments\", {}),\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Routing error: {str(e)}\")\n",
    "        return {\n",
    "            \"selected_tool\": null,\n",
    "            \"tool_arguments\": {},\n",
    "            \"status\": \"failed\",\n",
    "            \"tool_output\": f\"Routing error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "def tool_executor_node(state: RouterState) -> RouterState:\n",
    "    if not state[\"selected_tool\"]:\n",
    "        return {\n",
    "            \"tool_output\": \"No suitable tool found for this request.\",\n",
    "            \"status\": \"failed\"\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        tool = state[\"selected_tool\"]\n",
    "        args = state[\"tool_arguments\"]\n",
    "        \n",
    "        if tool == \"price_lookup\":\n",
    "            result = price_lookup(args.get(\"ticker\", \"\"))\n",
    "        elif tool == \"news_headlines\":\n",
    "            result = news_headlines(args.get(\"ticker\", \"\"), args.get(\"n\", 3))\n",
    "        elif tool == \"stat_ratios\":\n",
    "            result = stat_ratios(args.get(\"ticker\", \"\"))\n",
    "        else:\n",
    "            result = f\"Unknown tool: {tool}\"\n",
    "        \n",
    "        return {\n",
    "            \"tool_output\": result,\n",
    "            \"status\": \"success\" if not result.startswith(\"Error\") else \"failed\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"tool_output\": f\"Tool execution error: {str(e)}\",\n",
    "            \"status\": \"failed\"\n",
    "        }\n",
    "\n",
    "def response_composer_node(state: RouterState) -> RouterState:\n",
    "    if state[\"status\"] == \"failed\":\n",
    "        return {\n",
    "            \"final_output\": state.get(\"tool_output\", \"Request failed\"),\n",
    "            \"status\": \"failed\"\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(\n",
    "            f\"Format this response professionally:\\n\"\n",
    "            f\"User question: {state['user_input']}\\n\"\n",
    "            f\"Tool response: {state['tool_output']}\\n\"\n",
    "            f\"Final answer:\"\n",
    "        )\n",
    "        return {\n",
    "            \"final_output\": response,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"final_output\": state.get(\"tool_output\", \"Response formatting failed\"),\n",
    "            \"status\": \"failed\"\n",
    "        }\n",
    "\n",
    "# Build and run the graph\n",
    "workflow = StateGraph(RouterState)\n",
    "workflow.add_node(\"router\", router_node)\n",
    "workflow.add_node(\"execute\", tool_executor_node)\n",
    "workflow.add_node(\"compose\", response_composer_node)\n",
    "\n",
    "workflow.add_edge(\"router\", \"execute\")\n",
    "workflow.add_edge(\"execute\", \"compose\")\n",
    "workflow.add_edge(\"compose\", END)\n",
    "\n",
    "workflow.set_entry_point(\"router\")\n",
    "app = workflow.compile()\n",
    "\n",
    "# Demo with proper output handling\n",
    "demo_queries = [\n",
    "    \"Give me the P/E ratio for NVDA\",\n",
    "    \"What's the current price of Apple stock?\",\n",
    "    \"Show me recent news about Tesla\",\n",
    "    \"What are the financial ratios for Microsoft?\",\n",
    "    \"Tell me about the weather\"  # Should fail gracefully\n",
    "]\n",
    "\n",
    "def run_demo(query: str):\n",
    "    print(f\"\\nUser: {query}\")\n",
    "    result = app.invoke({\"user_input\": query, \"status\": \"pending\"})\n",
    "    \n",
    "    output = {\n",
    "        \"query\": query,\n",
    "        \"response\": result.get(\"final_output\", \"No response generated\"),\n",
    "        \"status\": result.get(\"status\", \"unknown\"),\n",
    "        \"tool_used\": result.get(\"selected_tool\", \"none\"),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_FILE, \"a\") as f:\n",
    "        f.write(json.dumps(output) + \"\\n\")\n",
    "    \n",
    "    print(f\"Assistant: {output['response']}\")\n",
    "    print(f\"Status: {output['status'].upper()}\")\n",
    "    print(f\"Tool used: {output['tool_used'].upper()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Financial Tool Router\")\n",
    "    \n",
    "    # Clear previous results\n",
    "    if os.path.exists(RESULTS_FILE):\n",
    "        os.remove(RESULTS_FILE)\n",
    "    \n",
    "    for query in demo_queries:\n",
    "        run_demo(query)\n",
    "    \n",
    "    print(\"\\nResults saved to:\", RESULTS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Automatic Chain Evaluator & Cost Ledger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Automatic Chain Evaluator & Cost Ledger\n",
    "from langchain.schema import BaseRetriever\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import re\n",
    "\n",
    "# Mock QA pairs for Apple's 10-K (would normally load from CSV)\n",
    "golden_qa_pairs = [\n",
    "    {\n",
    "        \"question\": \"What are Apple's primary product categories?\",\n",
    "        \"answer\": \"iPhone, Mac, iPad, Wearables, Services\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is Apple's gross margin percentage?\",\n",
    "        \"answer\": \"approximately 43 percent\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Where are Apple's main manufacturing partners located?\",\n",
    "        \"answer\": \"China, Taiwan, other parts of Asia\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many retail stores does Apple operate?\",\n",
    "        \"answer\": \"over 500 retail stores\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is Apple's approach to research and development?\",\n",
    "        \"answer\": \"significant ongoing investment in R&D\"\n",
    "    }\n",
    "]\n",
    "\n",
    "class MockRetriever(BaseRetriever):\n",
    "    \"\"\"Mock retriever that returns consistent docs for testing\"\"\"\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # Return mock documents based on query\n",
    "        if \"product categories\" in query.lower():\n",
    "            return [Document(page_content=\"Apple's primary products include iPhone, Mac, iPad, Wearables and Services.\")]\n",
    "        elif \"gross margin\" in query.lower():\n",
    "            return [Document(page_content=\"Apple's gross margin was approximately 43 percent last year.\")]\n",
    "        elif \"manufacturing partners\" in query.lower():\n",
    "            return [Document(page_content=\"Apple's manufacturing is concentrated in China, Taiwan and other parts of Asia.\")]\n",
    "        elif \"retail stores\" in query.lower():\n",
    "            return [Document(page_content=\"Apple operates over 500 retail stores worldwide.\")]\n",
    "        elif \"research and development\" in query.lower():\n",
    "            return [Document(page_content=\"Apple continues to make significant ongoing investment in research and development.\")]\n",
    "        else:\n",
    "            return [Document(page_content=\"Information not found in document.\")]\n",
    "\n",
    "class MockLLM:\n",
    "    \"\"\"Mock LLM that returns consistent answers for testing\"\"\"\n",
    "    def invoke(self, prompt: str):\n",
    "        if \"product categories\" in prompt:\n",
    "            return \"Apple's main products are iPhone, Mac, iPad, Wearables, and Services.\"\n",
    "        elif \"gross margin\" in prompt:\n",
    "            return \"Apple reported a gross margin of approximately 43 percent.\"\n",
    "        elif \"manufacturing partners\" in prompt:\n",
    "            return \"Apple's manufacturing is mainly in China, Taiwan, and other Asian countries.\"\n",
    "        elif \"retail stores\" in prompt:\n",
    "            return \"Apple has over 500 retail stores globally.\"\n",
    "        elif \"research and development\" in prompt:\n",
    "            return \"Apple invests significantly in ongoing research and development.\"\n",
    "        else:\n",
    "            return \"I don't know the answer to that question.\"\n",
    "\n",
    "class QAEvaluator:\n",
    "    def __init__(self, qa_pairs, retriever, llm):\n",
    "        self.qa_pairs = qa_pairs\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.results = []\n",
    "        self.total_cost = 0.0  # In dollars\n",
    "    \n",
    "    def normalize_text(self, text):\n",
    "        \"\"\"Normalize text for comparison\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def calculate_f1(self, pred, true):\n",
    "        \"\"\"Calculate F1 score between predicted and true answer\"\"\"\n",
    "        pred_tokens = set(self.normalize_text(pred).split())\n",
    "        true_tokens = set(self.normalize_text(true).split())\n",
    "        \n",
    "        if not pred_tokens or not true_tokens:\n",
    "            return 0.0\n",
    "        \n",
    "        common_tokens = pred_tokens & true_tokens\n",
    "        precision = len(common_tokens) / len(pred_tokens)\n",
    "        recall = len(common_tokens) / len(true_tokens)\n",
    "        \n",
    "        if (precision + recall) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    def mock_usage_metrics(self, text):\n",
    "        \"\"\"Mock function to simulate token usage tracking\"\"\"\n",
    "        # In a real implementation, we'd use response.usage\n",
    "        words = len(text.split())\n",
    "        prompt_tokens = words + 50  # Base prompt size\n",
    "        completion_tokens = words\n",
    "        \n",
    "        # Mock pricing: $0.0015 per 1K prompt tokens, $0.002 per 1K completion tokens\n",
    "        prompt_cost = (prompt_tokens / 1000) * 0.0015\n",
    "        completion_cost = (completion_tokens / 1000) * 0.002\n",
    "        \n",
    "        return {\n",
    "            \"prompt_tokens\": prompt_tokens,\n",
    "            \"completion_tokens\": completion_tokens,\n",
    "            \"total_cost\": prompt_cost + completion_cost\n",
    "        }\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate the QA chain against golden pairs\"\"\"\n",
    "        for pair in self.qa_pairs:\n",
    "            # Simulate running through QA chain\n",
    "            docs = self.retriever.get_relevant_documents(pair[\"question\"])\n",
    "            context = \" \".join([doc.page_content for doc in docs])\n",
    "            prompt = f\"Context: {context}\\nQuestion: {pair['question']}\\nAnswer:\"\n",
    "            \n",
    "            # Get LLM response\n",
    "            response = self.llm.invoke(prompt)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            f1 = self.calculate_f1(response, pair[\"answer\"])\n",
    "            usage = self.mock_usage_metrics(response)\n",
    "\n",
    "            self.results.append({\n",
    "                \"question\": question,\n",
    "                \"expected_answer\": expected_answer,\n",
    "                \"predicted_answer\": response,\n",
    "                \"f1_score\": f1,\n",
    "                \"usage\": usage\n",
    "            })\n",
    "\n",
    "        return self.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
